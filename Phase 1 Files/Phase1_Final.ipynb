{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:1.4em\" color='Grey'>Imports</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from colorama import Fore, Back, Style # Nice Colors\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:3.5em\" color='#FFEECF'>Misc. Functions</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='#D16C4B'>1: Load Image <b>Thresholded</b> </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#C4FCF1'>Parameters : imgPath </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#82AFFF'>Returns : Thresholded Image </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImageT(imgPath):\n",
    "    img = cv2.imread(imgPath) # 0 Because : We only need 1 color channel(?)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    if img.min() > 88:\n",
    "        _, thresh = cv2.threshold(img, img.mean(), 255, cv2.THRESH_BINARY)\n",
    "    else:\n",
    "        _, thresh = cv2.threshold(img, 88, 255, cv2.THRESH_BINARY)\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='#D16C4B'>Load Image <b>RGB</b> </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#C4FCF1'>Parameters : imgPath </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#82AFFF'>Returns : Image with 3 Color Channels</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImageRGB(imgPath):\n",
    "    img = cv2.imread(imgPath) \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='#D16C4B'>Find Contours </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#C4FCF1'>Parameters : img(Thresholded) </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#82AFFF'>Returns : Image's Contours </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findContours(imgT):\n",
    "    contours,heirarchy = cv2.findContours(imgT,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='#D16C4B'>Draw Contours - <b>Debugging Purposes</b></font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#C4FCF1'>Parameters : imgRGB,contours </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#82AFFF'>Returns : An Image With Contours Drawn </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='Purple'>CHECKING FUNCTIONS -- <b>IMAGE PREPROCESSING </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='#D16C4B'>Is Image Almost Invisible? </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#C4FCF1'>Parameters : img  </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#82AFFF'>Returns : True Or False </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isAlmostInvisible(img):\n",
    "    if (np.mean(img) > 195):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='#D16C4B'>Is Image Almost Invisible? ( Dark ) </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#C4FCF1'>Parameters : img  </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#82AFFF'>Returns : True Or False </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isAlmostInvisibleDark(img):\n",
    "    if (np.mean(img) < 40 ):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='#D16C4B'>Is Image Skewed? </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#C4FCF1'>Parameters : img </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#82AFFF'>Returns : True Or False </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawContours(imgRGB,contours):\n",
    "    for i in range(len(contours)):\n",
    "        cv2.drawContours(imgRGB,contours,i,(0,255,0),4)\n",
    "        i = i + 1\n",
    "    plt.imshow(imgRGB,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='#D16C4B'>Filter Contours V2 ---> V2 IS FOR DEBUGGING PURPOSES </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#C4FCF1'>Parameters : Contours </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#82AFFF'>Returns : True Or False </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterContoursV2(contours):\n",
    "    img_width  = 1012\n",
    "    img_height = 1012\n",
    "    potential_boxes = ([])\n",
    "    total_boxes = ([])\n",
    "    for contour in contours:\n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "        aspect_ratio = float(w) / h\n",
    "        if abs(aspect_ratio - 1) > 0.04: # Aspect ratio should be close to 1 if it is a square-like or rectangular shape\n",
    "            continue # Not what we are looking for.\n",
    "        min_size = min(w, h)\n",
    "        max_size = max(w, h)\n",
    "        if (min_size < 0.13 * img_width) or (max_size > 0.4 * img_width):  # Img_width [Should] be the same for all images.          \n",
    "            continue                    \n",
    "                                        # If the Rectangle is TOO small -> It is not the locator box.\n",
    "                                        # Probably doesn't need to be a % of the image. ( Could just use some number )\n",
    "\n",
    "        center_x, center_y = (x + x + w) // 2, (y + y + h) // 2\n",
    "        image_center_x, image_center_y = img_width // 2, img_height // 2\n",
    "\n",
    "        # Check for top-left, top-right, or bottom-left corner based on relative position\n",
    "        is_top_left = center_x < image_center_x * 0.4 and center_y < image_center_y * 0.4\n",
    "        is_top_right = center_x > image_center_x * 1.6 and center_y < image_center_y * 0.4\n",
    "        is_bottom_left = center_x < image_center_x * 0.4 and center_y > image_center_y * 1.6\n",
    "        is_bottom_right = ( center_x > (image_center_x * 1.6)) and (center_y > (image_center_y * 1.6))\n",
    "\n",
    "\n",
    "\n",
    "        if not (is_top_left or is_top_right or is_bottom_left): # Wrong Place.\n",
    "            if is_bottom_right:\n",
    "                total_boxes.append(contour)\n",
    "            continue\n",
    "\n",
    "        # Potential locator box based on heuristics\n",
    "        total_boxes.append(contour)\n",
    "        potential_boxes.append(contour)\n",
    "\n",
    "    if ( len(potential_boxes) == 9 ):\n",
    "        return (True,0,potential_boxes)\n",
    "    elif ( len(total_boxes) == 9):\n",
    "        return (False,1,total_boxes)\n",
    "    else:\n",
    "        return(False,2,total_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='#D16C4B'>Filter Contours </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#C4FCF1'>Parameters : Contours </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#82AFFF'>Returns : True Or False </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterContours(contours):\n",
    "    img_width  = 1012\n",
    "    img_height = 1012\n",
    "    potential_boxes = ([])\n",
    "    total_boxes = ([])\n",
    "    for contour in contours:\n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "        aspect_ratio = float(w) / h\n",
    "        if abs(aspect_ratio - 1) > 0.04: # Aspect ratio should be close to 1 if it is a square-like or rectangular shape\n",
    "            continue # Not what we are looking for.\n",
    "        min_size = min(w, h)\n",
    "        max_size = max(w, h)\n",
    "        if (min_size < 0.13 * img_width) or (max_size > 0.4 * img_width):  # Img_width [Should] be the same for all images.          \n",
    "            continue                    \n",
    "                                        # If the Rectangle is TOO small -> It is not the locator box.\n",
    "                                        # Probably doesn't need to be a % of the image. ( Could just use some number )\n",
    "\n",
    "        center_x, center_y = (x + x + w) // 2, (y + y + h) // 2\n",
    "        image_center_x, image_center_y = img_width // 2, img_height // 2\n",
    "\n",
    "        # Check for top-left, top-right, or bottom-left corner based on relative position\n",
    "        is_top_left = center_x < image_center_x * 0.4 and center_y < image_center_y * 0.4\n",
    "        is_top_right = center_x > image_center_x * 1.6 and center_y < image_center_y * 0.4\n",
    "        is_bottom_left = center_x < image_center_x * 0.4 and center_y > image_center_y * 1.6\n",
    "        is_bottom_right = ( center_x > (image_center_x * 1.6)) and (center_y > (image_center_y * 1.6))\n",
    "\n",
    "\n",
    "\n",
    "        if not (is_top_left or is_top_right or is_bottom_left): # Wrong Place.\n",
    "            if is_bottom_right:\n",
    "                total_boxes.append(contour)\n",
    "            continue\n",
    "\n",
    "        # Potential locator box based on heuristics\n",
    "        total_boxes.append(contour)\n",
    "        potential_boxes.append(contour)\n",
    "\n",
    "    if ( len(potential_boxes) == 9 ):\n",
    "        return (True,0)\n",
    "    elif ( len(total_boxes) == 9):\n",
    "        return (False,1)\n",
    "    else:\n",
    "        return(False,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='#D16C4B'>Draw Locator Boxes  </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#C4FCF1'>Parameters : an img </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#82AFFF'>Returns : The image with Locator Boxes Drawn In their assumed positions ( hopefully ) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawLocatorBoxes(img):\n",
    "    return cv2.bitwise_and(img,img,mask=whitemask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='#D16C4B'>Is Skewed </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#C4FCF1'>Parameters : img </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#82AFFF'>Returns : True Or False </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isSkewed(img):\n",
    "    try:\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    finally:\n",
    "        if img.min() > 88:\n",
    "            _, imageT = cv2.threshold(img, img.min(), 255, cv2.THRESH_BINARY)\n",
    "        else:\n",
    "            _, imageT = cv2.threshold(img, 88, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        cnts = findContours(imageT)\n",
    "\n",
    "        __,__,filteredCNTS = filterContoursV2(cnts)\n",
    "\n",
    "        minTheta = 0\n",
    "\n",
    "        for cnt in filteredCNTS:\n",
    "            (x,y),(width,height),theta = cv2.minAreaRect(cnt)\n",
    "            theta = theta - 90\n",
    "            if(theta <= minTheta):\n",
    "                minTheta = theta\n",
    "        if (minTheta <= -3 and minTheta != -90):\n",
    "            return (True,minTheta) # This Needs To Be Unskewed\n",
    "        return (False,minTheta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='#D16C4B'>Getting the mask for the DrawLocatorBoxes Function </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Top Left Done'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('TC/01.png')\n",
    "\n",
    "imgT = loadImageT('TC/01.png')\n",
    "\n",
    "\n",
    "contours = findContours(imgT)\n",
    "\n",
    "_,_,filteredcnts = filterContoursV2(contours)\n",
    "\n",
    "whitemask = np.ones((1012,1012),dtype=np.uint8)\n",
    "\n",
    "\n",
    "\"\"\"Bottom Left Drawing\"\"\"\n",
    "x1, y1, w1, h1 = cv2.boundingRect(filteredcnts[0])\n",
    "x2, y2, w2, h2 = cv2.boundingRect(filteredcnts[1])\n",
    "\n",
    "min_x = min(x1, x2)  # Leftmost X\n",
    "max_x = max(x1 + w1, x2 + w2)  # Rightmost X\n",
    "min_y = min(y1, y2)  # Topmost Y\n",
    "max_y = max(y1 + h1, y2 + h2)  # Bottommost Y\n",
    "\n",
    "\n",
    "\n",
    "for y in range(min_y, max_y):\n",
    "    for x in range(min_x, max_x):\n",
    "        whitemask[y, x] = 0  # Set pixel value to 0\n",
    "\n",
    "x1, y1, w1, h1 = cv2.boundingRect(filteredcnts[1])\n",
    "x2, y2, w2, h2 = cv2.boundingRect(filteredcnts[2])\n",
    "\n",
    "min_x = min(x1, x2)  # Leftmost X\n",
    "max_x = max(x1 + w1, x2 + w2)  # Rightmost X\n",
    "min_y = min(y1, y2)  # Topmost Y \n",
    "max_y = max(y1 + h1, y2 + h2)  # Bottommost Y\n",
    "\n",
    "\n",
    "\n",
    "for y in range(min_y, max_y):\n",
    "    for x in range(min_x, max_x):\n",
    "        whitemask[y, x] = 255  \n",
    "\n",
    "x, y, w, h = cv2.boundingRect(filteredcnts[2]) \n",
    "cv2.rectangle(whitemask, (x, y), (x + w, y + h), color=(0,0,0), thickness=-1) \n",
    "\n",
    "\"\"\"Bottom Left Done\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"Top Left Drawing\"\"\"\n",
    "x1, y1, w1, h1 = cv2.boundingRect(filteredcnts[3])\n",
    "x2, y2, w2, h2 = cv2.boundingRect(filteredcnts[4])\n",
    "\n",
    "min_x = min(x1, x2)  # Leftmost X\n",
    "max_x = max(x1 + w1, x2 + w2)  # Rightmost X\n",
    "min_y = min(y1, y2)  # Topmost Y \n",
    "max_y = max(y1 + h1, y2 + h2)  # Bottommost Y\n",
    "\n",
    "\n",
    "\n",
    "for y in range(min_y, max_y):\n",
    "    for x in range(min_x, max_x):\n",
    "        whitemask[y, x] = 0  # Set pixel value to 0\n",
    "\n",
    "x1, y1, w1, h1 = cv2.boundingRect(filteredcnts[4])\n",
    "x2, y2, w2, h2 = cv2.boundingRect(filteredcnts[5])\n",
    "\n",
    "min_x = min(x1, x2)  # Leftmost X\n",
    "max_x = max(x1 + w1, x2 + w2)  # Rightmost X\n",
    "min_y = min(y1, y2)  # Topmost Y \n",
    "max_y = max(y1 + h1, y2 + h2)  # Bottommost Y\n",
    "\n",
    "\n",
    "\n",
    "for y in range(min_y, max_y):\n",
    "    for x in range(min_x, max_x):\n",
    "        whitemask[y, x] = 255  \n",
    "\n",
    "x, y, w, h = cv2.boundingRect(filteredcnts[5]) \n",
    "cv2.rectangle(whitemask, (x, y), (x + w, y + h), color=(0,0,0), thickness=-1) \n",
    "\n",
    "\"\"\"Top Right Done\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"Top Left Drawing\"\"\"\n",
    "x1, y1, w1, h1 = cv2.boundingRect(filteredcnts[6])\n",
    "x2, y2, w2, h2 = cv2.boundingRect(filteredcnts[7])\n",
    "\n",
    "min_x = min(x1, x2)  # Leftmost X\n",
    "max_x = max(x1 + w1, x2 + w2)  # Rightmost X\n",
    "min_y = min(y1, y2)  # Topmost Y \n",
    "max_y = max(y1 + h1, y2 + h2)  # Bottommost Y\n",
    "\n",
    "\n",
    "\n",
    "for y in range(min_y, max_y):\n",
    "    for x in range(min_x, max_x):\n",
    "        whitemask[y, x] = 0  # Set pixel value to 0\n",
    "\n",
    "x1, y1, w1, h1 = cv2.boundingRect(filteredcnts[7])\n",
    "x2, y2, w2, h2 = cv2.boundingRect(filteredcnts[8])\n",
    "\n",
    "min_x = min(x1, x2)  # Leftmost X\n",
    "max_x = max(x1 + w1, x2 + w2)  # Rightmost X\n",
    "min_y = min(y1, y2)  # Topmost Y \n",
    "max_y = max(y1 + h1, y2 + h2)  # Bottommost Y\n",
    "\n",
    "\n",
    "\n",
    "for y in range(min_y, max_y):\n",
    "    for x in range(min_x, max_x):\n",
    "        whitemask[y, x] = 255  \n",
    "\n",
    "x, y, w, h = cv2.boundingRect(filteredcnts[8]) \n",
    "cv2.rectangle(whitemask, (x, y), (x + w, y + h), color=(0,0,0), thickness=-1) \n",
    "\n",
    "\"\"\"Top Left Done\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='#D16C4B'>Adjust Prespective ( With Related Functions )  </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#C4FCF1'>Parameters : an img </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#82AFFF'>Returns : The adjusted Image </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biggestContours(contours,numberOfContours=1):\n",
    "    # Sort the contours by area in descending order\n",
    "    contours = [np.array(contour) for contour in contours]\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:numberOfContours]\n",
    "    return contours\n",
    "\n",
    "def computeCenter(contours):\n",
    "    # Combine contours into one array\n",
    "    if len(contours)==0:\n",
    "        return None\n",
    "    \n",
    "    combined_contour = np.vstack(contours)\n",
    "\n",
    "    # Compute bounding box for the combined contours\n",
    "    x, y, w, h = cv2.boundingRect(combined_contour)\n",
    "\n",
    "    # Calculate center point of the bounding box\n",
    "    center_x = x + w // 2\n",
    "    center_y = y + h // 2\n",
    "\n",
    "    return (center_x, center_y)\n",
    "\n",
    "def find_missing_point(point1, point2, known_point):  \n",
    "    point1 = list(point1.ravel())\n",
    "    point2 = list(point2.ravel())\n",
    "    known_point = list(known_point.ravel())\n",
    "    # Determine the direction vector of the first line\n",
    "    direction_vector1 = np.array(point2) - np.array(point1)\n",
    "    \n",
    "    # Find the equation of the first line (y = mx + c)\n",
    "    m1 = direction_vector1[1] / direction_vector1[0]  # Slope\n",
    "    c1 = point1[1] - m1 * point1[0]  # Intercept\n",
    "    \n",
    "    \n",
    "    # Find the equation of the second line\n",
    "    m2 = m1  # Lines are parallel, so slopes are equal\n",
    "    c2 = known_point[1] - m2 * known_point[0]  # Intercept\n",
    "\n",
    "    # Calculate the length of the vector\n",
    "    vector_length = np.linalg.norm(direction_vector1)\n",
    "    \n",
    "    # Find the x-coordinate of the intersection point\n",
    "    intersection_x = known_point[0] + vector_length*np.cos(np.arctan(m1))\n",
    "    \n",
    "    # Find the y-coordinate of the intersection point\n",
    "    intersection_y = known_point[1] + vector_length*np.sin(np.arctan(m1))\n",
    "    \n",
    "    return intersection_x, intersection_y\n",
    "\n",
    "\n",
    "def AdjustPrespective(image):\n",
    "\n",
    "    contours= ut.locatorContours2(image=image,invertColors=False,showImages=False)\n",
    "\n",
    "    locatorBoxes=biggestContours(contours,numberOfContours=3)\n",
    "\n",
    "    centerPoint=computeCenter(locatorBoxes)\n",
    "    cv2.circle(center:=image.copy(), centerPoint, 10, (0, 255, 0), -1)\n",
    "\n",
    "\n",
    "    for i,locatorbox in enumerate(locatorBoxes):  # order all points in each box\n",
    "        locatorBoxes[i]=ut.orderPoints(locatorbox)\n",
    "\n",
    "    topLeft= topRight= bottomRight= bottomLeft = 0  # corner points for the whole qr code\n",
    "    for locator in locatorBoxes:\n",
    "        x, y, w, h = cv2.boundingRect(locator)\n",
    "\n",
    "        # Calculate center point of the bounding box\n",
    "        center_x,center_y = x + w // 2,y + h // 2\n",
    "        \n",
    "        if center_x> centerPoint[0] and center_y< centerPoint[1]:\n",
    "            topRight=locator[1]\n",
    "        \n",
    "        # elif center_x> centerPoint[0] and center_y> centerPoint[1]:\n",
    "            # bottomRight=locator[3]\n",
    "        \n",
    "        elif center_x< centerPoint[0] and center_y< centerPoint[1]:\n",
    "            topLeft=locator[0]\n",
    "        \n",
    "        elif center_x< centerPoint[0] and center_y> centerPoint[1]:\n",
    "            bottomLeft=locator[2]\n",
    "\n",
    "    cv2.circle(center, topRight.ravel(), 10, (0, 0, 255), -1)\n",
    "    cv2.circle(center, bottomLeft.ravel(), 10, (0, 0, 255), -1)\n",
    "    cv2.circle(center, topLeft.ravel(), 10, (0, 0, 255), -1)\n",
    "    # cv2.circle(center, bottomRight.ravel(), 10, (0, 0, 255), -1)\n",
    "    bottomRight=find_missing_point(topLeft,topRight,bottomLeft)\n",
    "    bottomRight=(int(round(bottomRight[0])),int(round(bottomRight[1])))\n",
    "    bottomRight=np.array([bottomRight])\n",
    "    cv2.circle(center, bottomRight.ravel(), 10, (0, 0, 255), -1)\n",
    "\n",
    "    width,height = 1012,1012\n",
    "\n",
    "\n",
    "    pts1 = np.float32([topLeft.ravel(),topRight.ravel(),bottomLeft.ravel(),bottomRight.ravel()])\n",
    "    pts2 = np.float32([[0,0],[0,width],[height,0],[width,height]])\n",
    "\n",
    "\n",
    "\n",
    "    matrix = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    output = cv2.warpPerspective(image,matrix,(width,height))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='Brown'>APPLYING FUNCTIONS -- <b>IMAGE PROCESSING </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='#D16C4B'>Rotate Image <b> 90 Degrees</font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#C4FCF1'>Parameters : img path </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#82AFFF'>Returns : rotated_Img </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotateImg(img): \n",
    "    rotated = cv2.rotate(img,cv2.ROTATE_90_CLOCKWISE)\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='#D16C4B'>Invert Colors </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#C4FCF1'>Parameters : img </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#82AFFF'>Returns : rotated_Img </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invertImg(img):\n",
    "    return cv2.bitwise_not(img) # Or 255 - img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='#D16C4B'>Mean Threshold </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#C4FCF1'>Parameters : img </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#82AFFF'>Returns : Img Mean Thresholded </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshHoldMean(img):\n",
    "    _, thresh = cv2.threshold(img, img.mean(), 255, cv2.ADAPTIVE_THRESH_MEAN_C)\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixSkew(img,angle):\n",
    "\n",
    "    (h, w) = img.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:2em\" color='#D16C4B'>Special Filter Sequence </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#C4FCF1'>Parameters : img </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#82AFFF'>Returns : fixedTC10 </font>\n",
    "\n",
    "<font style=\"font-size:1.2em\" color='#82AFFF'>This is definitely NOT for TC10 Only </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specialFilter(imgT):\n",
    "\n",
    "    filterapplied = cv2.medianBlur(imgT,3)\n",
    "\n",
    "    kernel1 = np.ones((3,3), np.uint8) \n",
    "    kernel2 = np.ones((9,9), np.uint8) \n",
    "    \n",
    "\n",
    "    finalImg = cv2.erode(filterapplied,kernel1)\n",
    "\n",
    "\n",
    "    finalImg = cv2.dilate(finalImg,kernel2)\n",
    "\n",
    "    return finalImg\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:3em\" color='#121212'>Pipeline - Phase 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m Test Case  1 doesn't need fixing\n",
      "\u001b[31m Test Case  2  Needs to be unskewed\n",
      "\u001b[32m Test Case  2  Fixed\n",
      "\u001b[31m Test Case  3  has all the locator boxes, But they are misalligned; Rotating...\n",
      "\u001b[31m Test Case  3  has all the locator boxes, But they are misalligned; Rotating...\n",
      "\u001b[32m Test Case  3  Rotation Fixed\n",
      "\u001b[33m Test Case  4  Is too dark\n",
      "\u001b[32m Test Case 4  Fixed\n",
      "\u001b[33m Test Case  4  needs to be Thresholded with the mean value and Have the locators re-drawn\n",
      "\u001b[32m Test Case 4  Fixed\n",
      "\u001b[33m Test Case  8  needs to be Thresholded with the mean value and Have the locators re-drawn\n",
      "\u001b[32m Test Case 8  Fixed\n",
      "\u001b[33m Test Case  10  needs to be Thresholded with the mean value and Have the locators re-drawn\n",
      "\u001b[32m Test Case 10  Fixed\n"
     ]
    }
   ],
   "source": [
    "# While image not correctly detected -->\n",
    "\n",
    "\"\"\"Image Paths\"\"\"\n",
    "img01_Path = 'TC/01.png'\n",
    "img02_Path = 'TC/02.png'\n",
    "img03_Path = 'TC/03.png'\n",
    "img04_Path = 'TC/04.png'\n",
    "img05_Path = 'TC/05.png'\n",
    "img06_Path = 'TC/06.png'\n",
    "img07_Path = 'TC/07.png'\n",
    "img08_Path = 'TC/08.png'\n",
    "img09_Path = 'TC/09.png'\n",
    "img10_Path = 'TC/10.png'\n",
    "img11_Path = 'TC/11.png'\n",
    "img12_Path = 'TC/12.png'\n",
    "img13_Path = 'TC/13.png'\n",
    "img14_Path = 'TC/14.png'\n",
    "\n",
    "\n",
    "\"\"\"Load Images\"\"\"\n",
    "img01 = cv2.imread(img01_Path)\n",
    "img02 = cv2.imread(img02_Path)\n",
    "img03 = cv2.imread(img03_Path)\n",
    "img04 = cv2.imread(img04_Path)\n",
    "img05 = cv2.imread(img05_Path)\n",
    "img06 = cv2.imread(img06_Path)\n",
    "img07 = cv2.imread(img07_Path)\n",
    "img08 = cv2.imread(img08_Path)\n",
    "img09 = cv2.imread(img09_Path)\n",
    "img10 = cv2.imread(img10_Path)\n",
    "img11 = cv2.imread(img11_Path)\n",
    "img12 = cv2.imread(img12_Path)\n",
    "img13 = cv2.imread(img13_Path)\n",
    "\n",
    "\"\"\"Images Loaded.\"\"\"\n",
    "\n",
    "img01T = loadImageT(img01_Path)\n",
    "img02T = loadImageT(img02_Path)\n",
    "img03T = loadImageT(img03_Path)\n",
    "img04T = loadImageT(img04_Path)\n",
    "img05T = loadImageT(img05_Path)\n",
    "img06T = loadImageT(img06_Path)\n",
    "img07T = loadImageT(img07_Path)\n",
    "img08T = loadImageT(img08_Path)\n",
    "img09T = loadImageT(img09_Path)\n",
    "img10T = loadImageT(img10_Path)\n",
    "img11T = loadImageT(img11_Path)\n",
    "img12T = loadImageT(img12_Path)\n",
    "img13T = loadImageT(img13_Path)\n",
    "\n",
    "\n",
    "imgVar01 = cv2.imread('TC/01.png')\n",
    "imgVar02 = cv2.imread('TC/02.png')\n",
    "imgVar03 = cv2.imread('TC/03.png')\n",
    "imgVar04 = cv2.imread('TC/04.png')\n",
    "imgVar05 = cv2.imread('TC/05.png')\n",
    "imgVar06 = cv2.imread('TC/06.png')\n",
    "imgVar07 = cv2.imread('TC/07.png')\n",
    "imgVar08 = cv2.imread('TC/08.png')\n",
    "imgVar09 = cv2.imread('TC/09.png')\n",
    "imgVar10 = cv2.imread('TC/10.png')\n",
    "imgVar11 = cv2.imread('TC/11.png')\n",
    "imgVar12 = cv2.imread('TC/12.png')\n",
    "imgVar13 = cv2.imread('TC/13.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "images = [(img01,img01T,imgVar01),(img02,img02T,imgVar02),(img03,img03T,imgVar03),(img04,img04T,imgVar04),(img05,img05T,imgVar05),(img06,img06T,imgVar06),\n",
    "        (img07,img07T,imgVar07),(img08,img08T,imgVar08),(img09,img09T,imgVar09),(img10,img10T,imgVar10),(img11,img11T,imgVar11),]\n",
    "\n",
    "\n",
    "for idx,img in enumerate(images):\n",
    "\n",
    "    img = img\n",
    "    img = list(img)\n",
    "    img[2] = cv2.cvtColor(img[2],cv2.COLOR_BGR2GRAY)\n",
    "    cnts = findContours(img[2])\n",
    "    \n",
    "    if (filterContours(cnts) == (True,0)): # Image doesn't need fixing\n",
    "        # Do Nothing\n",
    "        print(Fore.GREEN,'Test Case ',idx+1,'doesn\\'t need fixing')\n",
    "    if(isAlmostInvisibleDark(img[2])):\n",
    "        print(Fore.YELLOW,'Test Case ',idx+1, ' Is too dark')\n",
    "        img[2] = invertImg(img[2])\n",
    "        print(Fore.GREEN,'Test Case' ,idx+1,' Fixed')\n",
    "        cnts = findContours(img[2])\n",
    "    elif(filterContours(cnts) == (False,1)): # Image needs to be rotated\n",
    "        while(filterContours(cnts) == (False,1)):\n",
    "            print(Fore.RED,'Test Case ',idx+1,' has all the locator boxes, But they are misalligned; Rotating...')\n",
    "            rotated = rotateImg(img[2])\n",
    "            cnts = findContours(rotated)\n",
    "            img[2] = rotated\n",
    "        print(Fore.GREEN,'Test Case ',idx+1,' Rotation Fixed')\n",
    "    if (isSkewed(img[2])[0] == True):\n",
    "        __,angle = isSkewed(img[2])\n",
    "        print(Fore.RED,'Test Case ',idx+1, ' Needs to be unskewed')\n",
    "        img[2] = fixSkew(img[2],angle)\n",
    "        print(Fore.GREEN,'Test Case ',idx+1, ' Fixed')\n",
    "    \n",
    "    if(isAlmostInvisible(img[2])):\n",
    "        print(Fore.YELLOW,'Test Case ', idx+1, ' needs to be Thresholded with the mean value and Have the locators re-drawn')\n",
    "        img[2] = threshHoldMean(img[2])\n",
    "        img[2] = drawLocatorBoxes(img[2])\n",
    "        print(Fore.GREEN,'Test Case' ,idx+1,' Fixed')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedImages = []\n",
    "\n",
    "for idx,img in enumerate(images):\n",
    "    fixedImages.append(img[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:3em\" color='#FFFFFF'>Decoder </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#1#imporing image and making it black and white // and ploting it\n",
    "\n",
    "def Decode(img):\n",
    "    fig = plt.figure(figsize=(5, 5));\n",
    "    plt.xticks([], []);\n",
    "    plt.yticks([], []);\n",
    "    plt.title('Example QR code')\n",
    "    plt.imshow(img, cmap='gray');\n",
    "    print(\"Dimensions of the img:\",img.shape)\n",
    "\n",
    "    #2#reading queit zone // reading where is the white part that surrounds QR code and indicating the boundaries of the QR code\n",
    "    start_row = -1\n",
    "    start_col = -1\n",
    "    end_row = -1\n",
    "    end_col = -1\n",
    "\n",
    "    for row_index, row in enumerate(img):\n",
    "        for pixel in row:\n",
    "            if pixel != 255:\n",
    "                start_row = row_index\n",
    "                break\n",
    "        if start_row != -1:\n",
    "            break\n",
    "\n",
    "    for row_index, row in enumerate(img[::-1]):\n",
    "        for pixel in row:\n",
    "            if pixel != 255:\n",
    "                end_row = img.shape[0] - row_index\n",
    "                break\n",
    "        if end_row != -1:\n",
    "            break\n",
    "\n",
    "    for col_index, col in enumerate(cv2.transpose(img)):\n",
    "        for pixel in col:\n",
    "            if pixel != 255:\n",
    "                start_col = col_index\n",
    "                break\n",
    "        if start_col != -1:\n",
    "            break\n",
    "\n",
    "    for col_index, col in enumerate(cv2.transpose(img)[::-1]):\n",
    "        for pixel in col:\n",
    "            if pixel != 255:\n",
    "                end_col = img.shape[1] - col_index\n",
    "                break\n",
    "        if end_col != -1:\n",
    "            break\n",
    "\n",
    "    print(\"boundaries of QR code are:\", start_row, end_row, start_col, end_col)\n",
    "\n",
    "\n",
    "    #3#taking the indicated boundaries of the QR code plotting it, removing all white space surrounding it\n",
    "    qr_no_quiet_zone = img[start_row:end_row, start_col:end_col]\n",
    "    fig = plt.figure(figsize=(5, 5));\n",
    "    plt.xticks([], []);\n",
    "    plt.yticks([], []);\n",
    "    fig.get_axes()[0].spines[:].set_color('red');\n",
    "    fig.get_axes()[0].spines[:].set_linewidth(40);\n",
    "    fig.get_axes()[0].spines[:].set_position((\"outward\", 20))\n",
    "    plt.title('QR code without quiet zone', y = 1.15, color='red');\n",
    "    plt.imshow(qr_no_quiet_zone, cmap='gray');\n",
    "\n",
    "    # calculating dimensions of the QR code without the quiet zone (.shape get dimensions of the array)\n",
    "    print(\"Dimensions of the QR code without QZ:\",qr_no_quiet_zone.shape)\n",
    "\n",
    "\n",
    "    #using this QR code version, the qr have 21 unique square in each dimension .. so we'll make grid of 21x21 cell\n",
    "\n",
    "    grid_cells_num = 21\n",
    "\n",
    "    #check if qr code dimensions without QZ is square , if not make it square\n",
    "    newsize = max(qr_no_quiet_zone.shape[0], qr_no_quiet_zone.shape[1])\n",
    "    #ensure that the new size is multiple of 21:\n",
    "    newsize = grid_cells_num * np.ceil(newsize / grid_cells_num).astype(int)\n",
    "    qr_no_quiet_zone = cv2.resize(qr_no_quiet_zone, (newsize, newsize))\n",
    "    print(\"hello\")\n",
    "\n",
    "\n",
    "    grid_cell_size= qr_no_quiet_zone.shape[0]//grid_cells_num\n",
    "\n",
    "\n",
    "    print(\"Dimensions of the QR code after resizing:\",qr_no_quiet_zone.shape)\n",
    "\n",
    "\n",
    "    #4#now we grid the QR code into small boxes using .reshape\n",
    "    #grid_cells_num: number of rows and cols of the small boxes\n",
    "    #grid_cell_size: size of each small box\n",
    "    #.swapaxes : arrange the splitted small boxes correctly and aligned like the original QR code\n",
    "    qr_cells = qr_no_quiet_zone.reshape((\n",
    "        grid_cells_num,\n",
    "        grid_cell_size,\n",
    "        grid_cells_num,\n",
    "        grid_cell_size,\n",
    "    )).swapaxes(1, 2)\n",
    "    print(qr_cells.shape)\n",
    "\n",
    "\n",
    "    #plot the QR in small boxes each box framed in red frame\n",
    "    _, axes = plt.subplots(grid_cells_num, grid_cells_num, figsize=(5, 5))\n",
    "    for i, row in enumerate(axes):\n",
    "        for j, col in enumerate(row):\n",
    "            col.imshow(qr_cells[i][j], cmap=\"gray\", vmin=0, vmax=255)\n",
    "            col.get_xaxis().set_visible(False)\n",
    "            col.get_yaxis().set_visible(False)\n",
    "            col.spines[:].set_color('red')\n",
    "\n",
    "    #5#converting each grid cell to a numeric value such that / if common color white=1/ common color black =0\n",
    "    qr_cells_numeric = np.ndarray((grid_cells_num, grid_cells_num), dtype=np.uint8)\n",
    "    for i, row in enumerate(qr_cells):\n",
    "        for j, cell in enumerate(row):\n",
    "            qr_cells_numeric[i, j] = (np.median(cell) // 255)\n",
    "\n",
    "    print(qr_cells_numeric)\n",
    "\n",
    "\n",
    "    #INFORMATION EXTRACTION\n",
    "    #NOTEE: the QR code and our map have opposite ideas of what's black and what's white.\n",
    "    # So, we flip the bits (change 0 to 1 and 1 to 0) to make them match the real QR code\n",
    "\n",
    "    #6 . inspecting 8th row\n",
    "    #checking first 2 bits QR to indicate the error recovery level of the QR code\n",
    "    # We want row #8\n",
    "    qr_cells_numeric[8]\n",
    "\n",
    "    # The first two bits determine the error correction level\n",
    "    # Level L (Low)         [11]\t7%  of data bytes can be restored.\n",
    "    # Level M (Medium)      [10]\t15% of data bytes can be restored.\n",
    "    # Level Q (Quartile)    [01]\t25% of data bytes can be restored.\n",
    "    # Level H (High)        [00]\t30% of data bytes can be restored.\n",
    "    ecl = [int(not(c)) for c in qr_cells_numeric[8, 0:2]]\n",
    "    # Why \"not\"? Because the standard uses '1's for black and '0's for white\n",
    "    #\n",
    "    # \"A dark module is a binary one and a light module is a binary zero.\"\n",
    "    #  - ISO/IEC 18004:2000(E)\n",
    "    #\n",
    "    # In image processing, we use them the other way.. Hence the inversion\n",
    "    print(ecl)\n",
    "\n",
    "    #next 3 cells indicate mask used on the qr code\n",
    "    # Dictionary of all masks and their equivalent formulae\n",
    "    MASKS = {\n",
    "        \"000\": lambda i, j: (i * j) % 2 + (i * j) % 3 == 0,\n",
    "        \"001\": lambda i, j: (i / 2 + j / 3) % 2 == 0,\n",
    "        \"010\": lambda i, j: ((i * j) % 3 + i + j) % 2 == 0,\n",
    "        \"011\": lambda i, j: ((i * j) % 3 + i * j) % 2 == 0,\n",
    "        \"100\": lambda i, j: i % 2 == 0,\n",
    "        \"101\": lambda i, j: (i + j) % 2 == 0,\n",
    "        \"110\": lambda i, j: (i + j) % 3 == 0,\n",
    "        \"111\": lambda i, j: j % 3 == 0,\n",
    "    }\n",
    "\n",
    "    # the three cells after the ecl cells (converted to a string)\n",
    "    mask = [int(not(c)) for c in qr_cells_numeric[8, 2:5]]\n",
    "    mask_str = ''.join([str(c) for c in mask])\n",
    "    print(mask_str)\n",
    "\n",
    "\n",
    "    # Same row as above, but we want cells #5 and #7 (#6 is always set to 0),\n",
    "    #  followed by column #8 from cell #0 in it to cell #7 (and skipping #6)\n",
    "\n",
    "    fec = [] #fec= Format Error Correction //list where we will collect some infor about QR\n",
    "    #collect 5th and 7th cells in 8th row /and 8th column except 6th elements as it is always=1\n",
    "    fec.append(qr_cells_numeric[8, 5])\n",
    "    fec.append(qr_cells_numeric[8, 7])\n",
    "    fec.extend(qr_cells_numeric[0:6, 8])\n",
    "    fec.extend(qr_cells_numeric[7:9, 8])\n",
    "    fec = [int(not(c)) for c in fec]\n",
    "    print(fec)\n",
    "\n",
    "    # So in total we have the following 15 bits of format info from our QR code\n",
    "    #summary of the special settings the QR code uses to ensure it is read correctly and robustly.\n",
    "    print(ecl, mask, fec)\n",
    "\n",
    "\n",
    "\n",
    "    # Let's cross-check with our example\n",
    "    _, axes = plt.subplots(grid_cells_num, grid_cells_num, figsize=(5, 5))\n",
    "    for i, row in enumerate(axes):\n",
    "        for j, col in enumerate(row):\n",
    "\n",
    "            col.get_xaxis().set_visible(False)\n",
    "            col.get_yaxis().set_visible(False)\n",
    "            if (i == 8 and j <= 8) or (i <= 8 and j == 8):\n",
    "                if (i != 6) and (j != 6):\n",
    "                    col.imshow(qr_cells[i][j], cmap=\"gray\", vmin=0, vmax=255)\n",
    "                    col.spines[:].set_color('red')\n",
    "                    continue\n",
    "            col.imshow(qr_cells[i][j], cmap=\"gray\", vmin=-1275, vmax=510)\n",
    "\n",
    "    # However..... You need to XOR that with the \"format mask\": 101010000010010\n",
    "    ecl[0] ^= 1\n",
    "    mask[0] ^= 1\n",
    "    mask[2] ^= 1\n",
    "    fec[5] ^= 1\n",
    "    fec[8] ^= 1\n",
    "\n",
    "    # And now we print...\n",
    "    print(ecl, mask, fec)\n",
    "\n",
    "    # Before we proceed, let's write a function for masking to make our lives easier\n",
    "    UP, UP_ENC, DOWN, CW, CCW = range(5)  # A rather old-fashioned pythonic \"Enum\"\n",
    "\n",
    "    def apply_mask(data_start_i, data_start_j, direction):\n",
    "        '''\n",
    "        data_start_i/j represent the first cell's coords in its respective direction\n",
    "        direction is the masking direction, up(-enc)/down/clockwise/anti-clockwise\n",
    "        '''\n",
    "        result = []\n",
    "        row_offsets = []\n",
    "        col_offsets = []\n",
    "        if (direction in [UP, UP_ENC]):\n",
    "            row_offsets = [0,  0, -1, -1, -2, -2, -3, -3]\n",
    "            col_offsets = [0, -1,  0, -1,  0, -1,  0, -1]\n",
    "        if (direction == DOWN):\n",
    "            row_offsets = [0,  0,  1,  1,  2,  2,  3,  3]\n",
    "            col_offsets = [0, -1,  0, -1,  0, -1,  0, -1]\n",
    "        if (direction == CW):\n",
    "            row_offsets = [0,  0,  1,  1,  1,  1,  0,  0]\n",
    "            col_offsets = [0, -1,  0, -1, -2, -3, -2, -3]\n",
    "        if (direction == CCW):\n",
    "            row_offsets = [0,  0, -1, -1, -1, -1,  0,  0]\n",
    "            col_offsets = [0, -1,  0, -1, -2, -3, -2, -3]\n",
    "\n",
    "        for i, j in zip(row_offsets, col_offsets):\n",
    "            cell = qr_cells_numeric[data_start_i+i, data_start_j+j]\n",
    "            result.append(int(cell if MASKS[mask_str](data_start_i+i, data_start_j+j) else not cell))\n",
    "\n",
    "        return result[:4] if direction == UP_ENC else result\n",
    "\n",
    "    #DATA ENCODING\n",
    "    enc = apply_mask(grid_cells_num-1, grid_cells_num-1, UP_ENC)\n",
    "    print(enc)\n",
    "\n",
    "    len = apply_mask(grid_cells_num-3, grid_cells_num-1, UP)\n",
    "    print(len)\n",
    "\n",
    "    data_starting_indices = [\n",
    "        [grid_cells_num-7, grid_cells_num-1, UP],\n",
    "        [grid_cells_num-11, grid_cells_num-1, CCW],\n",
    "        [grid_cells_num-10, grid_cells_num-3, DOWN],\n",
    "        [grid_cells_num-6, grid_cells_num-3, DOWN],\n",
    "        [grid_cells_num-2, grid_cells_num-3, CW],\n",
    "        [grid_cells_num-3, grid_cells_num-5, UP],\n",
    "        [grid_cells_num-7, grid_cells_num-5, UP],\n",
    "        [grid_cells_num-11, grid_cells_num-5, CCW],\n",
    "        [grid_cells_num-10, grid_cells_num-7, DOWN],\n",
    "        [grid_cells_num-6, grid_cells_num-7, DOWN],\n",
    "        [grid_cells_num-2, grid_cells_num-7, CW],\n",
    "        [grid_cells_num-3, grid_cells_num-9, UP],\n",
    "        [grid_cells_num-7, grid_cells_num-9, UP],\n",
    "        [grid_cells_num-11, grid_cells_num-9, UP],\n",
    "        [grid_cells_num-16, grid_cells_num-9, UP],\n",
    "        [grid_cells_num-20, grid_cells_num-9, CCW],\n",
    "        [grid_cells_num-19, grid_cells_num-11, DOWN],\n",
    "        [grid_cells_num-14, grid_cells_num-11, DOWN],\n",
    "        [grid_cells_num-10, grid_cells_num-11, DOWN],\n",
    "        [grid_cells_num-6, grid_cells_num-11, DOWN],\n",
    "        # Hmm..? I actually don't know how to proceed now lol\n",
    "    ]\n",
    "\n",
    "    ans = ''\n",
    "    for a, b, d in data_starting_indices:\n",
    "        bits = apply_mask(a, b, d)\n",
    "        bit_string = ''.join([str(bit) for bit in bits])\n",
    "        if bit_string[:4] == \"0000\":\n",
    "            print(f'{bit_string[:4]} = 0 (NULL TERMINATOR)')\n",
    "            break\n",
    "        ans += chr(int(bit_string, 2)) # converts to binary to int, then to ASCII\n",
    "        print(f'{bit_string} = {ans[-1]}')\n",
    "\n",
    "    print(f'\\nDecoded string: {ans}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
